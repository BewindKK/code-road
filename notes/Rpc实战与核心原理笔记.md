# RPC实战与核心原理

## 0. 

**什么是RPC？**

 RPC 是帮助我们屏蔽网络编程细节，实现调用远程方法就跟调用本地（同一个项目中的方法）一样的体验，我们不需要因为这个方法是远程调用就需要编写很多与业务无关的代码

**RPC 的作用就是体现在这样两个方面：**

- 屏蔽远程调用跟本地调用的区别，让我们感觉就是调用项目内的方法；
- 隐藏底层网络通信的复杂性，让我们更专注于业务逻辑。

## 1. 为什么要学习RPC

**只要涉及到网络通信，我们就可能用到 RPC**

**RPC 是解决分布式系统通信问题的一大利器**

> 例 1：大型分布式应用系统可能会依赖消息队列、分布式缓存、分布式数据库以及统一配置中心等，应用程序与依赖的这些中间件之间都可以通过 RPC 进行通信。比如 etcd，它作为一个统一的配置服务，客户端就是通过 gRPC 框架与服务端进行通信的
>
> 例 2：我们经常会谈到的容器编排引擎 Kubernetes，它本身就是分布式的，Kubernetes的 kube-apiserver 与整个分布式集群中的每个组件间的通讯，都是通过 gRPC 框架进行的。

分布式系统中的网络通信一般都会采用四层的 TCP 协议或七层的 HTTP 协议，在我的了解中，前者占大多数，这主要得益于 TCP 协议的稳定性和高效性。

而 RPC 对网络通信的整个过程做了完整包装，在搭建分布式系统时，它会使**网络通信逻辑**的开发变得更加简单，同时也会让网络通信变得更加安全可靠。

使用 RPC 就可以像调用本地一样发起远程调用，用它可以解决通信问题，这时候我们肯定要去学序列化、编解码以及网络传输这些内容。

RPC 还有更吸引人的点，它真正强大的地方是它的**治理功能**，比如连接管理、健康检测、负载均衡、优雅启停机、异常重试、业务分组以及熔断限流等等。

## 2. RPC 的通信流程

![RPCPrinciple](https://xingqiu-tuchuang-1256524210.cos.ap-shanghai.myqcloud.com/205/RPCPrinciple.png)

- **网络传输模块**： RPC 常用于业务系统之间的数据交互

  - **可靠性：** RPC 一般默认采用 TCP 来传输

- **序列化：**网络传输数据必须是二进制数据

  - 调用方持续地把请求参数序列化成二进制后，经过 TCP 传输给了服务提供方。服务提供方从 TCP 通道里面收到二进制数据

- **协议：**数据格式约定内容

  - 大多数的协议会分成两部分，分别是数据头和消息体。数据头一般用于身份识别，包括协议标识、数据大小、请求类型、序列化类型等信息；消息体主要是请求的业务参数信息和扩展属性等。

- **动态代理：**通过字节码增强对方法进行拦截增强，以便于增加需要的额外处理逻辑。**屏蔽掉 RPC 细节，让使用方只需要关注业务接口。**

  - 由服务提供者给出业务接口声明，在调用方的程序里面，RPC 框架根据调用的服务接口提

    前生成动态代理实现类，并通过依赖注入等技术注入到声明了该接口的相关业务逻辑里面。

    该代理实现类会拦截所有的方法调用，在提供的方法处理逻辑里面完成一整套的远程调用，

    并把远程调用结果返回给调用方，这样调用方在调用远程方法的时候就获得了像调用本地接

    口一样的体验

**RPC 在架构中的位置**

应用之间会通过 RPC 进行通信，可以说 RPC 对应的是整个分布式应用系统，就像是“经络”一样的存在

**RPC 框架能够帮助我们解决系统拆分后的通信问题，并且能让我们像调用本地一样去调用远程方法。**利用 RPC 我们不仅可以很方便地将应用架构从“单体”演进成“微服务化”，而且还能解决实际开发过程中的效率低下、系统耦合等问题，这样可以使得我们的系统架构整体清晰、健壮，应用可运维度增强。

用在了很多其他场景，比如：发 MQ、分布式缓存、数据库等。

## 3. 协议

 **RPC 协议就是围绕应用层协议展开的**



**协议的作用**

在传输过程中，RPC 并不会把请求参数的所有二进制数据整体一下子发送到对端机器上，中间可能会拆分成好几个数据包，也可能会合并其他请求的数据包（合并的前提是同一个 TCP 连接上的数据）

 TCP 通道里面收到很多的二进制数据，那这时候怎么**识别出哪些二进制**是第一个请求的呢？们加上标点，完成断句就好了。为了避免语义不一致的事情发生，我们就需要在发送请求的时候设定一个边界，然后在收到请求的时候**按照这个设定的边界进行数据分割**。这个边界语义的表达，就是我们所说的协议



**直接用HTTP协议不行吗？**

RPC 更多的是负责应用间的通信，所以性能要求相对更高。HTTP 协议的数据包大小相对请求数据本身要大很多，又需要加入很多无用的内容，比如换行符号、回车符等。还有一个更重要的原因是，HTTP 协议属于无状态协议，客户端无法对请求和响应进行关联，每次请求都需要重新建立连接。

对于要求高性能的 RPC 来说，HTTP 协议基本很难满足需求，所以RPC 会选择设计更紧凑的私有协议。



**怎么设计一个私有 RPC 协议呢？**

**完成 RPC 通信的时候，在协议里面需要放哪些内容。**

**消息边界**：RPC 每次发请求发的大小都是不固定的，所以我们的协议必须能让接收方正确地读出不定长的内容。

> 先固定一个长度（比如4 个字节）用来保存整个请求数据大小，这样收到数据的时候，我们先读取固定长度的位置里面的值，值的大小就代表协议体的长度，接着再根据值的大小来读取协议体的数据
>
> ![image-20220330224719232](Rpc实战与核心原理笔记Assets/image-20220330224719232.png)

只实现了正确的断句效果，在 RPC 里面还行不通。因为对于服务提供方来说，他是不知道这个协议体里面的二进制数据是通过哪种序列化方式生成的

**序列化方式单独拿出来，类似协议长度一样用固定的长度存放-->协议头**

![image-20220330224910585](Rpc实战与核心原理笔记Assets/image-20220330224910585.png)

**可扩展的协议**

**那我把参数加在不定长的协议体里面行不行？协议体里面会放一些扩展属性。**

> 没错，协议体里面是可以加新的参数，但这里有一个关键点，就是协议体里面的内容都是经过序列化出来的，也就是说你要获取到你参数的值，就必须把整个协议体里面的数据经过反序列化出来。但在某些场景下，这样做的代价有点高啊！

**关键在于让协议头支持可扩展**

整体协议就变成了三部分内容：固定部分、协议头内容、协议体内容，前两部分我们还是可以统称为“协议头”

![image-20220330225228240](Rpc实战与核心原理笔记Assets/image-20220330225228240.png)

## 4. 序列化

**什么是序列化与反序列化？**

序列化就是将对象转换成二进制数据的过程，而反序列就是反过来将二进制转换为对象的过程。

 **RPC 框架为什么需要序列化呢？**

因为网络传输的数据必须是二进制数据，所以在 RPC 调用中，对入参对象与返回值对象进行序列化与反序列化是一个必须的过程。

### **哪些常用的序列化？**

**JDK** **原生序列化**

序列化具体的实现是由 ObjectOutputStream 完成的，而反序列化的具体实现是由 ObjectInputStream 完成的。

**JDK 的序列化过程是怎样完成的呢？**

![image-20220331170259357](Rpc实战与核心原理笔记Assets/image-20220331170259357.png)

序列化过程就是在读取对象数据的时候，不断加入一些特殊分隔符，这些特殊分隔符用于在反序列化过程中截断用。

**实际上任何一种序列化框架，核心思想就是设计一种序列化协议**，将对象的类型、属性类型、属性值一一按照固定的格式写到二进制字节流中来完成序列化，再按照固定的格式一一读出对象的类型、属性类型、属性值，通过这些信息重新创建出一个新的对象，来完成反序列化。



**JSON**

JSON 可能是我们最熟悉的一种序列化格式了，JSON 是典型的 Key-Value 方式，没有数据类型，是一种文本型序列化框架，JSON 的具体格式和特性



**应用上**还是很广泛的，无论是前台 Web 用 Ajax 调用、用磁盘存储文本类型的数据，还是基于 HTTP 协议的 RPC 框架通信，都会选择 JSON 格式。



**JSON 进行序列化有这样两个问题**

- JSON 进行序列化的**额外空间开销比较大**，对于大数据量服务这意味着需要巨大的内存和磁盘开销；
- JSON **没有类型**，但像 Java 这种强类型语言，需要通过**反射统一解决**，所以性能不会太好。

如果 RPC 框架选用 JSON 序列化，服务提供者与服务调用者之间传输的数据量要相对较小，否则将严重影响性能。



**Hessian**

Hessian 是动态类型、二进制、紧凑的，并且可跨语言移植的一种序列化框架。Hessian 协议要比 JDK、JSON 更加紧凑，性能上要比 JDK、JSON 序列化高效很多，而且生成的字节数也更小。

```java
Student student = new Student(); 
student.setNo(101); 
student.setName("HESSIAN"); 

//把student对象转化为byte数组
ByteArrayOutputStream bos = new ByteArrayOutputStream(); 
Hessian2Output output = new Hessian2Output(bos); 
output.writeObject(student); 
output.flushBuffer(); 
byte[] data = bos.toByteArray(); 
bos.close(); 

//把刚才序列化出来的byte数组转化为student对象
ByteArrayInputStream bis = new ByteArrayInputStream(data); 
Hessian2Input input = new Hessian2Input(bis); 
Student deStudent = (Student) input.readObject(); 
input.close(); 
System.out.println(deStudent);
```

相对于 JDK、JSON，由于 Hessian 更加高效，生成的字节数更小，有非常好的兼容性和稳定性，所以 Hessian 更加适合作为 RPC 框架远程通信的序列化协议

 **Hessian 本身也有问题**，官方版本对 Java 里面一些常见对象的类型不支持

Linked 系列，LinkedHashMap、LinkedHashSet 等，但是可以通过扩展

CollectionDeserializer 类修复；

Locale 类，可以通过扩展 ContextSerializerFactory 类修复；

Byte/Short 反序列化的时候变成 Integer。



**Protobuf**

Protobuf 是 Google 公司内部的混合语言数据标准，是一种轻便、高效的结构化数据存储

格式，可以用于结构化数据序列化，支持 Java、Python、C++、Go 等语言。Protobuf

使用的时候需要定义 IDL（Interface description language），然后使用不同语言的 IDL

编译器，生成序列化工具类，它的优点是：

序列化后体积相比 JSON、Hessian 小很多；

IDL 能清晰地描述语义，所以足以帮助并保证应用程序之间的类型不会丢失，无需类似

XML 解析器；

序列化反序列化速度很快，不需要通过反射获取类型；

消息格式升级和兼容性不错，可以做到向后兼容。



使用代码示例如下：

```java
1 /** 2 * 3 * // IDl 文件格式
4 * synax = "proto3"; 5 * option java_package = "com.test"; 6 * option java_outer_classname = "StudentProtobuf"; 7 * 8 * message StudentMsg { 9 * //序号
10 * int32 no = 1; 11 * //姓名
12 * string name = 2; 13
14 * } 15 * 16 */ 1718 StudentProtobuf.StudentMsg.Builder builder = StudentProtobuf.StudentMsg.newBuil 19 builder.setNo(103); 20 builder.setName("protobuf"); 2122 //把student对象转化为byte数组
23 StudentProtobuf.StudentMsg msg = builder.build(); 24 byte[] data = msg.toByteArray(); 2526 //把刚才序列化出来的byte数组转化为student对象
27 StudentProtobuf.StudentMsg deStudent = StudentProtobuf.StudentMsg.parseFrom(dat 28 System.out.println(deStudent);
```

Protobuf 非常高效，但是对于具有反射和动态能力的语言来说，这样用起来很费劲，这一

点就不如 Hessian，比如用 Java 的话，这个预编译过程不是必须的，可以考虑使用

Protostuff。

Protostuff 不需要依赖 IDL 文件，可以直接对 Java 领域对象进行反 / 序列化操作，在效率

上跟 Protobuf 差不多，生成的二进制格式和 Protobuf 是完全相同的，可以说是一个 Java

版本的 Protobuf 序列化框架。但在使用过程中，我遇到过一些不支持的情况，也同步给

你：

不支持 null；

ProtoStuff 不支持单纯的 Map、List 集合对象，需要包在对象里面。

### **RPC** **框架中如何选择序列化**

**性能和效率：**序列化与反序列化过程是 RPC 调用的一个必须过程，那么序列化与反序列化的性能和效率势必将直接关系到 RPC 框架整体的性能和效率。

**空间开销**，也就是序列化之后的二进制数据的体积大小。序列化后的字节数据体积越小，网络传输的数据量就越小，传输数据的速度也就越快，由于 RPC 是远程调用，那么网络传输的速度将直接关系到请求响应的耗时。



**序列化协议的通用性和兼容性**：通用性和兼容性的优先级会更高

他是会直接关系到服务调用的稳定性和可用率的，对于服务的性能来说，服务的**可靠性显然更加重要**。我们更加看重这种序列化协议在版本升级后的**兼容性是否很好**，是否支持更多的对象类型，是否是跨平台、跨语言的，是否有很多人已经用过并且踩过了很多的坑，其次我们才会去考虑性能、效率和空间开销。



**序列化协议的安全性**

![image-20220331172150404](Rpc实战与核心原理笔记Assets/image-20220331172150404.png)



#### 总结一下这几个序列化协议

首选的还是 Hessian 与 Protobuf，因为他们在性能、时间开销、空间开销、通用性、兼容性和安全性上，都满足了我们的要求。其中 Hessian 在使用上更加方便，在对象的兼容性上更好；Protobuf 则更加高效，通用性上更有优势。

### **RPC** **框架在使用时要注意哪些问题？**

**对象构造得过于复杂：**属性很多，并且存在多层的嵌套，比如 A 对象关联 B 对象，B 对象又聚合 C 对象，C 对象又关联聚合很多其他对象，对象依赖关系过于复杂。序列化框架在序列化与反序列化对象时，对象越复杂就越浪费性能，消耗 CPU，这会严重影响 RPC 框架整体的性能；另外，对象越复杂，在序列化与反序列化的过程中，出现问题的概率就越高。

**对象过于庞大：**我经常遇到业务过来咨询，为啥他们的 RPC 请求经常超时，排查后发现他们的入参对象非常得大，比如为一个大 List 或者大 Map，序列化之后字节长度达到了上兆字节。这种情况同样会严重地浪费了性能、CPU，并且序列化一个如此大的对象是很耗费时间的，这肯定会直接影响到请求的耗时。

**使用序列化框架不支持的类作为入参类：**比如 Hessian 框架，他天然是不支持LinkHashMap、LinkedHashSet 等，而且大多数情况下最好不要使用第三方集合类，如Guava 中的集合类，很多开源的序列化框架都是优先支持编程语言原生的对象。因此如果入参是集合类，应尽量选用原生的、最为常用的集合类，如 HashMap、ArrayList。

**对象有复杂的继承关系：**大多数序列化框架在序列化对象时都会将对象的属性一一进行序列化，当有继承关系时，会不停地寻找父类，遍历属性。就像问题 1 一样，对象关系越复杂，就越浪费性能，同时又很容易出现序列化上的问题。



在 RPC 框架的使用过程中，我们要尽量构建简单的对象作为入参和返回值对象，避免上述问题



## 5. 网络通信

网络通信是整个 RPC 调用流程的基础。

所谓的两台 PC 机之间的网络通信，实际上就是两台 PC 机对网络 IO 的操作。

### 常见的网络IO模型

**阻塞IO（blocking IO）**

应用进程发起 IO 系统调用后，应用进程被阻塞，转到内核空间处理。之后，内核开始等待数据，等待到数据之后，再将内核中的数据拷贝到用户内存中，整个 IO 处理完毕后返回进程。最后应用的进程解除阻塞状态，运行业务逻辑。

> 这个流程就好比我们去餐厅吃饭，我们到达餐厅，向服务员点餐，之后要一直在餐厅等待后厨将菜做好，然后服务员会将菜端给我们，我们才能享用

**IO多路复用（IO multiplexing）**

多路复用 IO 是在高并发场景中使用最为广泛的一种 IO 模型，如 Java 的 NIO、Redis、Nginx 的底层实现就是此类 IO 模型的应用，经典的 Reactor 模式也是基于此类 IO 模型。



**什么是 IO 多路复用呢？**

多路就是指多个通道，也就是多个网络连接的 IO，而复用就是指多个通道复用在一个复用器上。

**多个网络连接的 IO 可以注册到一个复用器（select）上**，当用户进程调用了 select，那么整个进程会被阻塞。同时，内核会“监视”所有 select 负责的 socket，当任何一个 socket 中的数据准备好了，select 就会返回。这个时候用户进程再调用 read 操作，将数据从内核中拷贝到用户进程。

当用户进程发起了 select 调用，进程会被阻塞，当发现该 select 负责的 socket 有准备好的数据时才返回，之后才发起一次 read，整个流程要比阻塞 IO 要复杂，似乎也更浪费性能。但它最大的优势在于，用户可以在一个线程内同时处理多个 socket 的 IO 请求。用户可以注册多个 socket，然后不断地调用 select 读取被激活的 socket，即可达到在同一个线程内同时处理多个 IO 请求的目的。

> 同样好比我们去餐厅吃饭，这次我们是几个人一起去的，我们专门留了一个人在餐厅排号等位，其他人就去逛街了，等排号的朋友通知我们可以吃饭了，我们就直接去享用了



**为什么说阻塞** **IO** **和** **IO** **多路复用最为常用？**

1、**系统内核的支持以及编程语言的支持。**

在系统内核的支持上，现在大多数系统内核都会支持阻塞 IO、非阻塞 IO 和 IO 多路复用，但像信号驱动 IO、异步 IO，只有高版本的 Linux 系统内核才会支持。

2、在编程语言上，无论 C++ 还是 Java，在高性能的网络编程框架的编写上，大多数都是基于 Reactor 模式，其中最为典型的便是 Java 的 Netty 框架，而 Reactor 模式是基于 IO 多路复用的。当然，在非高并发场景下，同步阻塞 IO 是最为常见的。



**RPC** **框架在网络通信上倾向选择哪种网络** **IO** **模型？**

**IO 多路复用更适合高并发的场景**，可以用较少的进程（线程）处理较多的 socket 的 IO 请求，但使用难度比较高。当然高级的编程语言支持得还是比较好的，比如 Java 语言有很多的开源框架对 Java 原生 API 做了封装，如 Netty 框架，使用非常简便；而 GO 语言，语言本身对 IO 多路复用的封装就已经很简洁了。

阻塞 IO 与 IO 多路复用相比，**阻塞 IO** 每处理一个 socket 的 IO 请求都会阻塞进程（线程），但使用难度较低。在并发量较低、业务逻辑只需要同步进行 IO 操作的场景下，阻塞IO 已经满足了需求，并且不需要发起 select 调用，开销上还要比 IO 多路复用低。

RPC 调用在大多数的情况下，是一个高并发调用的场景，考虑到系统内核的支持、编程语言的支持以及 IO 模型本身的特点，在 RPC 框架的实现中，在网络通信的处理上，我们会选择 IO 多路复用的方式。开发语言的网络通信框架的选型上，我们最优的选择是基于Reactor 模式实现的框架，如 Java 语言，首选的框架便是 Netty 框架（Java 还有很多其他 NIO 框架，但目前 Netty 应用得最为广泛），并且在 Linux 环境下，也要开启 epoll 来提升系统性能（Windows 环境下是无法开启 epoll 的，因为系统内核不支持）。



**什么是零拷贝？**

**等待数据**，就是系统内核在等待网卡接收到数据后，把数据写到内核中；而**拷贝数据**，就是系统内核在获取到数据后，将数据拷贝到用户进程的空间中。

![image-20220331230023348](Rpc实战与核心原理笔记Assets/image-20220331230023348.png)

应用进程的每一次写操作，都会把数据写到用户空间的缓冲区中，再由 CPU 将数据拷贝到系统内核的缓冲区中，之后再由 DMA 将这份数据拷贝到网卡中，最后由网卡发送出去。

一次写操作数据要拷贝两次才能通过网卡发送出去，而用户进程的读操作则是将整个流程反过来，数据同样会拷贝两次才能让应用程序读取到数据。



**减少进程间的数据拷贝，提高数据传输的效率呢？**

**零拷贝（Zero-copy）技术。**

所谓的零拷贝，就是取消用户空间与内核空间之间的数据拷贝操作，应用进程每一次的读写操作，可以通过一种方式，直接将数据写入内核或从内核中读取数据，再通过 DMA 将内核中的数据拷贝到网卡，或将网卡中的数据 copy 到内核。

![image-20220331230304286](Rpc实战与核心原理笔记Assets/image-20220331230304286.png)

零拷贝有两种解决方式，分别是 mmap+write 方式和 sendfile 方式，其核心原理都是通过虚拟内存来解决的。



**零拷贝带来的好处就是避免没必要的 CPU 拷贝，让 CPU 解脱出来去做其他的事，同时也减少了 CPU 在用户空间与内核空间之间的上下文切换，从而提升了网络通信效率与应用程序的整体性能。**



**Netty** **中的零拷贝**

Netty 的零拷贝则不大一样，他完全站在了用户空间上，也就是 JVM 上，它的零拷贝主要是偏向于数据操作的优化上。

**那么 Netty 这么做的意义是什么呢？**

在传输过程中，RPC 并不会把请求参数的所有二进制数据整体一下子发送到对端机器上，中间可能会拆分成好几个数据包，也可能会合并其他请求的数据包，所以消息都需要有边界。那么一端的机器收到消息之后，就需要对数据包进行处理，根据边界对数据包进行分割和合并，最终获得一条完整的消息。

那收到消息后，**对数据包的分割和合并，是在用户空间完成，还是在内核空间完成的呢？**

当然是在**用户空间，**因为对数据包的处理工作都是由应用程序来处理的，那么这里有没有可能存在数据的拷贝操作？可能会存在，当然不是在用户空间与内核空间之间的拷贝，是用户空间内部内存中的拷贝处理操作。**Netty 的零拷贝就是为了解决这个问题，在用户空间对数据操作进行优化。**



**那么 Netty 是怎么对数据操作进行优化的呢？**

Netty 提供了 CompositeByteBuf 类，它可以将多个 ByteBuf 合并为一个逻辑上的 ByteBuf，避免了各个 ByteBuf 之间的拷贝。

ByteBuf 支持 slice 操作，因此可以将 ByteBuf 分解为多个共享同一个存储区域的ByteBuf，避免了内存的拷贝。

通过 wrap 操作，我们可以将 byte[] 数组、ByteBuf、ByteBuffer 等包装成一个 NettyByteBuf 对象, 进而避免拷贝操作。



Netty 的 ByteBuffer 可以采用 Direct Buffers，使用堆外直接内存进行 Socketd 的读写操作，最终的效果与我刚才讲解的虚拟内存所实现的效果是一样的。

Netty 还提供 FileRegion 中包装 NIO 的 FileChannel.transferTo() 方法实现了零拷贝，这与 Linux 中的 sendfile 方式在原理上也是一样的。



而 Netty 的零拷贝与操作系统的零拷贝是有些区别的，Netty 的零拷贝偏向于用户空间中

对数据操作的优化，这对处理 TCP 传输中的拆包粘包问题有着重要的意义，对应用程序处

理请求数据与返回数据也有重要的意义。



在 RPC 框架的开发与使用过程中，我们要深入了解网络通信相关的原理知识，尽量做到零

拷贝，如使用 Netty 框架；我们要合理使用 ByteBuf 子类，做到完全零拷贝，提升 RPC

框架的整体性能。

## 6. 动态代理

> 我们在编写业务逻辑的时候，如果要调用提供方的接口，我们就只需要通过依赖注入的方式把接口注入到项目中就行了，然后在代码里面直接调用接口的方法 。接口里并不会包含真实的业务逻辑，业务逻辑都在服务提供方应用里，但我们通过调用接口方法，确实拿到了想要的结果。**这里面用到的核心技术就是前面说的动态代理。**

RPC 会自动给接口生成一个代理类，当我们在项目中注入接口的时候，运行过程中实际绑定的是这个接口生成的代理类。这样在接口方法被调用的时候，它实际上是被生成代理类拦截到了，这样我们就可以在生成的代理类里面，加入远程调用逻辑。

![image-20220401111700643](Rpc实战与核心原理笔记Assets/image-20220401111700643.png)

### 实现的原理

例子：

```java
/** 
 * 要代理的接口
 */  
public interface Hello {
    String say();
} 
    /**  
    * 真实调用对象
	*/ 
    public class RealHello { 
        public String invoke(){ 
            return "i'm proxy"; 
        } 
    } 

/**
 * JDK代理类生成
 */ 
public class JDKProxy implements InvocationHandler { 22 
    private Object target; 2324 
        JDKProxy(Object target) { 25 
        this.target = target; 26 
                                } 2728
    @Override 29 
    public Object invoke(Object proxy, Method method, Object[] paramValues) { 
        30 return ((RealHello)target).invoke(); 31
    } 32
                                                   } 
/** 
 * 测试例子
 */
public class TestProxy { 
    public static void main(String[] args){ 
        // 构建代理器
JDKProxy proxy = new JDKProxy(new RealHello()); 
        ClassLoader classLoader = ClassLoaderUtils.getCurrentClassLoader(); 
        // 把生成的代理类保存到文件
System.setProperty("sun.misc.ProxyGenerator.saveGeneratedFiles","true");
    
    // 生成代理类
Hello test = (Hello) Proxy.newProxyInstance(classLoader, new Class[]{He 
    // 方法调用
System.out.println(test.say()); 
                                                                    } 
                                            }
```

给 Hello 接口生成一个动态代理类，并调用接口 say() 方法，但真实返回的值居然是来自 RealHello 里面的 invoke() 方法返回值。



 **Proxy.newProxyInstance**

![image-20220401112428477](Rpc实战与核心原理笔记Assets/image-20220401112428477.png)

### 实现方法

单纯从代理功能上来看，JDK 默认的代理功能是有一定的局限性的，它要求被代理的类只能是接口。原因是因为生成的代理类会继承 Proxy 类，但 Java 是不支持多重继承的。

这个限制在 RPC 应用场景里面还是挺要紧的，因为对于服务调用方来说，在使用 RPC 的时候本来就是面向接口来编程的，这个我们刚才在前面已经讨论过了。使用 JDK 默认的代理功能，**最大的问题就是性能问题**。它生成后的代理类是使用反射来完成方法调用的，而这种方式相对直接用编码调用来说，性能会降低，但好在 JDK8 及以上版本对反射调用的性能有很大的提升



Byte Buddy 则属于后起之秀，在很多优秀的项目中，像 Spring、Jackson 都用到了 Byte Buddy 来完成底层代理。相比 Javassist，Byte Buddy 提供了更容易操作的 API，编写的代码可读性更高。更重要的是，生成的代理类执行速度比 Javassist 更快。



**动态代理选型**

因为代理类是在运行中生成的，那么**代理框架生成代理类的速度**、生成代理类的字节码大小等等，都会影响到其性能——生成的字节码越小，运行所占资源就越小。

还有就是我们生成的代理类，是用于接口方法请求拦截的，所以每次调用接口方法的时候，都会执行生成的代理类，这时生成的**代理类的执行效率就需要很高效。**

最后一个是从我们的**使用角度**出发的，我们肯定希望选择一个**使用起来很方便的代理类框架**，比如我们可以考虑：API 设计是否好理解、社区活跃度、还有就是依赖复杂度等等。

## 7. gRPC

gRPC 是由 Google 开发并且开源的一款高性能、跨语言的 RPC 框架，当前支持 C、Java和 Go 等语言gRPC 有很多特点，比如跨语言，通信协议是基于标准的 HTTP/2 设计的，序列化支持 PB（Protocol Buffer）和JSON，

整个调用示例如下图所示：

![image-20220401113447470](Rpc实战与核心原理笔记Assets/image-20220401113447470.png)

## 8. 架构设计：设计一个灵活的RPC框架

![image-20220401114351548](Rpc实战与核心原理笔记Assets/image-20220401114351548.png)

**可拓展**

我们设计 RPC 框架是一样的，我们不可能在开始时就面面俱到。

那有没有更好的方式来解决这些问题呢？这就是我们接下来要讲的**插件化架构**。



**在 RPC 框架里面，我们是怎么支持插件化架构的呢？**

`我们可以将每个功能点抽象成一个接口，将这个接口作为插件的契约，然后把这个功能的接口与功能的实现分离，并提供接口的默认实现。`



> 在 Java 里面，JDK 有自带的 SPI（Service Provider Interface）服务发现机制，它可以动态地为某个接口寻找服务实现。使用 SPI 机制需要在 Classpath 下的 META INF/services 目录里创建一个以服务接口命名的文件，这个文件里的内容就是这个接口的具体实现类
>
> 但在实际项目中，我们其实很少使用到 JDK 自带的 SPI 机制，首先它不能按需加载，ServiceLoader 加载某个接口实现类的时候，会遍历全部获取，也就是接口的实现类得全部载入并实例化一遍，会造成不必要的浪费。另外就是扩展如果依赖其它的扩展，那就做不到自动注入和装配，这就很难和其他框架集成，比如扩展里面依赖了一个 Spring Bean，原生的 Java SPI 就不支持

加上了插件功能之后，我们的 RPC 框架就包含了两大核心体系——**核心功能体系与插件体系**，如下图所示：

![image-20220401114939416](Rpc实战与核心原理笔记Assets/image-20220401114939416.png)

**这时，整个架构就变成了一个微内核架构**，我们将每个功能点抽象成一个接口，将这个接口作为插件的契约，然后把这个功能的接口与功能的实现分离并提供接口的默认实现。

**优势**

- 首先它的**可扩展性很好**，实现了开闭原则，用户可以非常方便地通过插件扩展实现自己的功能，而且不需要修改核心功能的本身；
- 其次就是保持了**核心包的精简**，依赖外部包少，这样可以有效减少开发人员引入 RPC 导致的包版本冲突问题。



## # 课后思考

### 在 RPC 里面，我们是怎么实现请求跟响应关联的呢？

以 Dubbo 为例，消费者发送请求时，使用 AtomicLong 自增，产生一个 消息 ID。由于

Dubbo 底层 IO 操作是异步的，Dubbo 发送请求之后，需要阻塞等待消费者返回信息。

消费者会将消息 ID 保存到 Map 结构中,。为了保证请求响应可以一一对应，这就需要提供

者返回的响应信息带上请求者消息 ID。 通过响应的消息 ID，通过 上面提到 Map 存储数

据，就能找到对应的请求。

